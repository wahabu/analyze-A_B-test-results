{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle act Report\n",
    "\n",
    "#### By: Bawahab Abdulwahab - Makkah - KSA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset that we wrangled and make our analyzed on it are the tweet archive of Twitter user **@dog_rates**, also known as **WeRateDogs**, and is a Twitter account that rates people's dogs with a humorous comment about the dog. \n",
    "\n",
    "In This project we do a data wrangling on archive Twitter datasets, we gathered data from a variety of sources and in a variety of formats, assessed its quality and tidiness and cleaned the datasets from the issues we found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries And Programs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our anlayzed, we used the python language to write our codes, Also, we work on Jupyter Notebook. And We used these following packages and libraries For our analyzed and Visualized :\n",
    "\n",
    "- Anaconda\n",
    "- pandas\n",
    "- NumPy\n",
    "- tweepy\n",
    "- json\n",
    "- requests    \n",
    "- matplotlib\n",
    "- seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In gathering step we Load three datasets with three different way:\n",
    "\n",
    "load dataset from (existing file), (programmatically using the Requests library), (using Tweepy).\n",
    "\n",
    "> #### Existing File\n",
    "We load the dataset of twitter archive file `twitter-archive-enhanced-2.csv` used the method **read_csv()**.\n",
    "\n",
    "> #### Programmatically using the Requests library\n",
    "We Download by Requests library the file `image-predictions.tsv` and we used methods **get()**, **open()**, and **write()** to the output file without sit data in memory by **response.content** function.\n",
    "\n",
    "> #### Using Tweepy\n",
    "After I send to Twitter to ask them to allow me to use their API to collect data from WeRateDogs account, they rejected my request. so, We put the codes to get the tweets by twitter API without running it.\n",
    "And to get the extra information the columns \"Retweet Count and Favorite Count\" we use the exist file from udacity `tweet_json.txt` to get that information we need.\n",
    "and we read file using **open()** method and create an empty list then used for lope to insert the data line by line in the list used the method **append()**. Then we collect the two columns data we want uesed **map()** method then insert data in new dataframe.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After explore our datasets used the methods **head()**, **info()**, **describe()**, **value_counts()**, **sum()** and **isnull()** we found some issues that need to cleaning and fix them. we summary our finding and classification issues to **Quality** and **Tidiness** as bellow:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality\n",
    "\n",
    "#### Twitter archive dataframe\n",
    "\n",
    "- The column **name**,  have name value \"None\" is a null value actually, we need to convert it to NaN.\n",
    "- The column **rating_numerator** have invalid values.\n",
    "- The column **rating_numerator** need change format.\n",
    "- The column **stages**,  have name \"None\" is a null value actually, we need to convert it to NaN.\n",
    "- The format for `stages` column from string to category.\n",
    "- Remove the tweets that has been retweet as its not original.\n",
    "- Remove unnecessary coulmns.\n",
    "\n",
    "#### Twitter image dataframe\n",
    "\n",
    "- There are unnecessary underscoreb **(_)** between words in the columns **p1**,**p2** and **p3**.\n",
    "- There are inconsisitent capital words in columns **p1**,**p2** and **p3**.\n",
    "\n",
    "#### Twitter API And JSON dataframe\n",
    "\n",
    "- Remove the tweets rows that don't have dog ratings.\n",
    "\n",
    "### Tidiness\n",
    "\n",
    "- The dog stage spilled in 4 columns **doggo**, **floofer**, **pupper** and **puppo** we need to merge them.\n",
    "- Our three dataframes they are from the same observation unit we need to merge them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step in our cleaning we make a copies for our datasets to dont make changes in the orginal datasets.\n",
    "\n",
    "we section our finding issue as define, code, and test and put each issue under word **\"issues\"**\n",
    "\n",
    "**Define:**  we explain our issues and the sloution we will make it.\n",
    "\n",
    "**Code:** we put here our codes to solve the issues \n",
    "\n",
    "**Test:** we check the fixing issues \n",
    "\n",
    "#### And we used some methods in our cleaning step they are: \n",
    "\n",
    "value_counts - copy() - replace() - lower() - head() - isnull() - sum() - display() - option_context() - str.contains() - astype() - drop - notnull() - shape - info() - max() - merge() - reduce() - apply() - append() - reset_index() - to_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing and Visualizing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We made three Insites in file name `Analyzi_Visualiz.csv` and make our Analysis and Visualiz on twitter archive.\n",
    "\n",
    "### Our First Insite \n",
    "\n",
    "We want to see the count of dogs stages in the tweets and what stage showing as the most in WeRateDogs Twitter account.\n",
    "We visualized this insite by bar plot.\n",
    "\n",
    "### Our Second Insite\n",
    "\n",
    "We want to see the count of dogs types in the tweets and the most type in WeRateDogs Twitter account.\n",
    "We visualized this insite by bar horizontal plot.\n",
    "\n",
    "### Our Third Insite\n",
    "\n",
    "The relationship between retweet count and favorite count.\n",
    "We visualized this insite by scatter regplot plot.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We Store the clean DataFrames in file with the main one named `twitter_archive_master.csv`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
